{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFile\n",
    "import face_recognition\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "ROOT_DIR = os.path.abspath(os.curdir)\n",
    "\n",
    "# Set seed to sample same set of images each time\n",
    "random.seed(61)\n",
    "\n",
    "# We need nose bridge and chin to fit mask on a face\n",
    "KEY_FACIAL_FEATURES = {'nose_bridge', 'chin'}\n",
    "MODEL = 'cnn' # cnn or hog cnn is slower than hog but more accurate in terms of face detection \n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(os.curdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masked_face(image_path, mask_path):\n",
    "    # Convert image into format that face_recognition library understands \n",
    "    face_image_np = face_recognition.load_image_file(image_path)\n",
    "    \n",
    "    # Recognize face boundaries from an image \n",
    "    face_locations = face_recognition.face_locations(face_image_np, model=MODEL)\n",
    "    \n",
    "    # Find facial landmarks from the recognized face to fit mask\n",
    "    face_landmarks = face_recognition.face_landmarks(face_image_np, face_locations)\n",
    "    has_key_face_landmarks = check_face_landmarks(face_landmarks)\n",
    "    \n",
    "    if has_key_face_landmarks:\n",
    "        face_img = Image.fromarray(face_image_np)\n",
    "        mask_img = Image.open(mask_path)\n",
    "        face_mask_img = mask_face(face_img, mask_img, face_landmarks[0])\n",
    "        cropped_face_mask_img = crop_image(face_mask_img, face_locations[0])\n",
    "        return cropped_face_mask_img\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def check_face_landmarks(face_landmarks):\n",
    "    # Check whether there is a face_landmark\n",
    "    if len(face_landmarks) > 0:\n",
    "        # Check whether face_landmarks include all key facial features to fit mask\n",
    "        if face_landmarks[0].keys() >= KEY_FACIAL_FEATURES:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def mask_face(face_img, mask_img, face_landmark):\n",
    "    nose_bridge = face_landmark['nose_bridge']\n",
    "    nose_point = nose_bridge[len(nose_bridge) * 1 // 4]\n",
    "    nose_v = np.array(nose_point)\n",
    "\n",
    "    chin = face_landmark['chin']\n",
    "    chin_len = len(chin)\n",
    "    chin_bottom_point = chin[chin_len // 2]\n",
    "    chin_bottom_v = np.array(chin_bottom_point)\n",
    "    chin_left_point = chin[chin_len // 8]\n",
    "    chin_right_point = chin[chin_len * 7 // 8]\n",
    "\n",
    "    # split mask and resize\n",
    "    width = mask_img.width\n",
    "    height = mask_img.height\n",
    "    width_ratio = 1.2\n",
    "    new_height = int(np.linalg.norm(nose_v - chin_bottom_v))\n",
    "\n",
    "    # left\n",
    "    mask_left_img = mask_img.crop((0, 0, width // 2, height))\n",
    "    mask_left_width = get_distance_from_point_to_line(chin_left_point, nose_point, chin_bottom_point)\n",
    "    mask_left_width = int(mask_left_width * width_ratio)\n",
    "    mask_left_img = mask_left_img.resize((mask_left_width, new_height))\n",
    "\n",
    "    # right\n",
    "    mask_right_img = mask_img.crop((width // 2, 0, width, height))\n",
    "    mask_right_width = get_distance_from_point_to_line(chin_right_point, nose_point, chin_bottom_point)\n",
    "    mask_right_width = int(mask_right_width * width_ratio)\n",
    "    mask_right_img = mask_right_img.resize((mask_right_width, new_height))\n",
    "\n",
    "    # merge mask\n",
    "    size = (mask_left_img.width + mask_right_img.width, new_height)\n",
    "    mask_img = Image.new('RGBA', size)\n",
    "    mask_img.paste(mask_left_img, (0, 0), mask_left_img)\n",
    "    mask_img.paste(mask_right_img, (mask_left_img.width, 0), mask_right_img)\n",
    "\n",
    "    # rotate mask\n",
    "    angle = np.arctan2(chin_bottom_point[1] - nose_point[1], chin_bottom_point[0] - nose_point[0])\n",
    "    rotated_mask_img = mask_img.rotate(angle, expand=True)\n",
    "\n",
    "    # calculate mask location\n",
    "    center_x = (nose_point[0] + chin_bottom_point[0]) // 2\n",
    "    center_y = (nose_point[1] + chin_bottom_point[1]) // 2\n",
    "\n",
    "    offset = mask_img.width // 2 - mask_left_img.width\n",
    "    radian = angle * np.pi / 180\n",
    "    box_x = center_x + int(offset * np.cos(radian)) - rotated_mask_img.width // 2\n",
    "    box_y = center_y + int(offset * np.sin(radian)) - rotated_mask_img.height // 2\n",
    "\n",
    "    # add mask\n",
    "    face_img.paste(mask_img, (box_x, box_y), mask_img)\n",
    "    return face_img\n",
    "\n",
    "def get_distance_from_point_to_line(point, line_point1, line_point2):\n",
    "    distance = np.abs((line_point2[1] - line_point1[1]) * point[0] +\n",
    "                      (line_point1[0] - line_point2[0]) * point[1] +\n",
    "                      (line_point2[0] - line_point1[0]) * line_point1[1] +\n",
    "                      (line_point1[1] - line_point2[1]) * line_point1[0]) / \\\n",
    "               np.sqrt((line_point2[1] - line_point1[1]) * (line_point2[1] - line_point1[1]) +\n",
    "                       (line_point1[0] - line_point2[0]) * (line_point1[0] - line_point2[0]))\n",
    "    return int(distance)\n",
    "\n",
    "def save(save_dir, fname, face_img):\n",
    "    dest_path = os.path.join(save_dir, fname)\n",
    "    face_img.save(dest_path)\n",
    "    \n",
    "def crop_image(img, face_location):\n",
    "    top, right, bottom, left = face_location\n",
    "    return img.crop((left, top, right, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 601/2500.0 [06:44<16:05,  1.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n009028_0220_02.jpg file is passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500.0 [30:21<00:00,  1.37it/s] \n"
     ]
    }
   ],
   "source": [
    "available_masks = glob.glob(os.path.join(ROOT_DIR, 'data', 'mask-templates', \"*.png\"))\n",
    "\n",
    "available_sample_face_imgs = glob.glob(os.path.join(ROOT_DIR, 'data', 'sampled_face_images', \"*.jpg\"))\n",
    "random.shuffle(available_sample_face_imgs)\n",
    "target_n_masked_face_imgs = len(available_sample_face_imgs) / 2\n",
    "n_masked_images = 0\n",
    "\n",
    "# Create a directory to save masked / not masked images\n",
    "masked_img_dir = os.path.join(ROOT_DIR, 'data', 'train', 'masked')\n",
    "not_masked_img_dir = os.path.join(ROOT_DIR, 'data', 'train', 'not_masked')\n",
    "os.makedirs(os.path.join(ROOT_DIR, 'data', 'train'), exist_ok=True)\n",
    "os.makedirs(masked_img_dir, exist_ok=True)\n",
    "os.makedirs(not_masked_img_dir, exist_ok=True)\n",
    "\n",
    "pbar = tqdm(total=target_n_masked_face_imgs)\n",
    "while n_masked_images < target_n_masked_face_imgs:\n",
    "    image_path = available_sample_face_imgs.pop()\n",
    "    fname  = os.path.basename(image_path)\n",
    "    \n",
    "    random_mask_path = random.choice(available_masks)\n",
    "    try:\n",
    "        masked_face = create_masked_face(image_path, random_mask_path)\n",
    "    except:\n",
    "        print('{} file is passed'.format(fname))\n",
    "    if masked_face is not None:\n",
    "        save(masked_img_dir, fname, masked_face)\n",
    "        n_masked_images += 1\n",
    "        pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2467/2467 [26:51<00:00,  1.53it/s] \n"
     ]
    }
   ],
   "source": [
    "for remaining_img_path in tqdm(available_sample_face_imgs):\n",
    "    # Convert image into format that face_recognition library understands \n",
    "    face_image_np = face_recognition.load_image_file(remaining_img_path)\n",
    "    \n",
    "    # Recognize face boundaries from an image \n",
    "    face_locations = face_recognition.face_locations(face_image_np, model=MODEL)\n",
    "\n",
    "    img = Image.open(remaining_img_path)\n",
    "    if len(face_locations) > 0:\n",
    "        cropped_img = crop_image(img, face_locations[0])\n",
    "        fname = os.path.basename(remaining_img_path)\n",
    "        save(not_masked_img_dir, fname, cropped_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model-zoo",
   "language": "python",
   "name": "model-zoo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
