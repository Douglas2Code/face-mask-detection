{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a mask/no mask classification model\n",
    "\n",
    "Notebook to train a mask/no mask classification model.   \n",
    "The input are images of faces that are already cropped. \n",
    "\n",
    "We plan to use this notebook with three kinds of images:  \n",
    "    - Images of faces without mask  \n",
    "    - Images of faces with an artificial mask  \n",
    "    - Images of faces with a real mask\n",
    "\n",
    "Note: for now we have done this with a sample from the MAFA dataset (http://www.escience.cn/people/geshiming/mafa.html).  \n",
    "I have randomly marked half of the masked faces as being artificially masked, just to already get the code for the separate accuracies.  \n",
    "As we'll plug in our own data later, no tuning is done yet and only minimal training.\n",
    "\n",
    "\n",
    "We train a MobileNetV2 base followed by a Global Average Pooling layer, 2 fully connected layers and finally a sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "import keras \n",
    "\n",
    "from sklearn import metrics \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (224,224)\n",
    "batch_size = 32\n",
    "lr = 0.01\n",
    "n_epochs = 1\n",
    "\n",
    "# csv files with paths to training and validation images\n",
    "# these files contain a column with the class (masked or not_masked)\n",
    "# they also contain a column that indicates if it is a real mask or artificially generated\n",
    "train_csv = 'tmp_data/train.csv'\n",
    "val_csv = 'tmp_data/val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNet(weights='imagenet',include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512,activation='relu')(x) \n",
    "x = Dense(512,activation='relu')(x) \n",
    "x = Dense(256,activation='relu')(x) \n",
    "preds = Dense(1,activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only train the final fully connected layers, not the mobilenet base\n",
    "for layer in model.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_df = pd.read_csv(train_csv)\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
    "                                                    target_size=target_size,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary',\n",
    "                                                    classes=['masked', 'not_masked'],\n",
    "                                                    shuffle=True,\n",
    "                                                    x_col='image',\n",
    "                                                    y_col='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_df = pd.read_csv(val_csv)\n",
    "val_generator = val_datagen.flow_from_dataframe(val_df, \n",
    "                                                shuffle=False,\n",
    "                                                target_size=target_size,\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode='binary',\n",
    "                                                classes=['masked', 'not_masked'],\n",
    "                                                x_col='image',\n",
    "                                                y_col='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "step_size_train = train_generator.n//train_generator.batch_size\n",
    "step_size_val = val_generator.n//val_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubsetAccuracy(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    We want to monitor accuracy in the validation set separately for real and artificial face masks.\n",
    "    This callback will print this to the output, and store the values for each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, val_gen=None, val_df=None):\n",
    "        self.val_gen = val_gen\n",
    "        self.val_df = val_df\n",
    "        \n",
    "        artificial_idx = val_df.index[val_df.artificial == \"yes\"].tolist()\n",
    "        real_masked_idx = val_df.index[(val_df.artificial == \"no\") & (val_df.label == \"masked\")].tolist()\n",
    "        non_masked_idx = val_df.index[val_df.label == \"not_masked\"].tolist()\n",
    "        \n",
    "        # the 'real' validation subset consists of all non-masked images, \n",
    "        # and all real masked images\n",
    "        self.real_eval_idxs = non_masked_idx + real_masked_idx\n",
    "        self.real_eval_ground_truth = [1] * len(non_masked_idx) + [0] * len(real_masked_idx)\n",
    "        \n",
    "        # the 'artificial' validation subset consists of all non-masked images,\n",
    "        # and all artificial masked images\n",
    "        self.artificial_eval_idxs = non_masked_idx + artificial_idx\n",
    "        self.artificial_eval_ground_truth = [1] * len(non_masked_idx) + [0] * len(artificial_idx)\n",
    "        \n",
    "        # these will store accuracies for different sets after each epoch\n",
    "        self.acc_all = []\n",
    "        self.acc_real = []\n",
    "        self.acc_artificial = []\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        pred = self.model.predict_generator(self.val_gen)\n",
    "        pred = [x[0] > 0.5 for x in pred]\n",
    "\n",
    "        accuracy_all = metrics.accuracy_score(self.val_gen.labels, pred)\n",
    "        print(f\"The accuracy for the full validation set is {accuracy_all:.3f}\")\n",
    "                \n",
    "        real_eval_preds = [pred[idx] for idx in self.real_eval_idxs]\n",
    "        accuracy_real = metrics.accuracy_score(self.real_eval_ground_truth, real_eval_preds)\n",
    "        print(f\"The accuracy for the validation set with only real masked faces is: {accuracy_real:.3f}\")\n",
    "\n",
    "        artifical_eval_preds = [pred[idx] for idx in self.artificial_eval_idxs]\n",
    "        accuracy_artificial = metrics.accuracy_score(self.artificial_eval_ground_truth, artifical_eval_preds)\n",
    "        print(f\"The accuracy for the validation set with only artificial masked faces is: {accuracy_artificial:.3f}\")\n",
    "        \n",
    "        self.acc_all.append(accuracy_all)\n",
    "        self.acc_real.append(accuracy_real)\n",
    "        self.acc_artificial.append(accuracy_artificial)\n",
    "          \n",
    "subset_acc = SubsetAccuracy(val_generator, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "62/62 [==============================] - 74s 1s/step - loss: 2.2648 - accuracy: 0.8155 - val_loss: 0.1554 - val_accuracy: 0.9335\n",
      "The accuracy for the full validation set is 0.933\n",
      "The accuracy for the validation set with only real masked faces is: 0.924\n",
      "The accuracy for the validation set with only artificial masked faces is: 0.933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f489c392c90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator, steps_per_epoch=step_size_train, epochs=n_epochs, validation_data=val_generator, validation_steps=step_size_val, callbacks=[subset_acc])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
